{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-sFdKKsCi_JN"
      },
      "source": [
        "# Final Notebook\n",
        "\n",
        "This notebook is your search engine. \n",
        "\n",
        "For testing your work, we will run each cell. Thus, your code we'll have to fit the structure expected.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uZV0BVIKi_JR"
      },
      "source": [
        "## Initialisation\n",
        "\n",
        "- Install libraries (if you use Colab and needed),\n",
        "- Import the modules,\n",
        "- Declare global variable\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U-J-SulpjRkQ",
        "outputId": "8066b541-3adc-479b-c58b-133df5532348"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.3)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.2.0)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2022.10.31)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.65.0)\n",
            "[nltk_data] Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]   Package brown is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package conll2000 to /root/nltk_data...\n",
            "[nltk_data]   Package conll2000 is already up-to-date!\n",
            "[nltk_data] Downloading package movie_reviews to /root/nltk_data...\n",
            "[nltk_data]   Package movie_reviews is already up-to-date!\n",
            "Finished.\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (4.11.2)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4) (2.4.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install nltk\n",
        "!python -m textblob.download_corpora\n",
        "!pip install beautifulsoup4\n",
        "!pip install sentence-transformers --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y6NEJS4sjk1M",
        "outputId": "94764d38-6171-4071-d839-86ce9f0bda00"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "from bs4 import BeautifulSoup\n",
        "import re\n",
        "import math\n",
        "import numpy as np\n",
        "import pickle\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.corpus import stopwords"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SHiXGDEkjsqI",
        "outputId": "04b23e60-91a0-4ded-d25c-c7bf7e277633"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# Only if you use Colab\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "z1KYM5rki_JS"
      },
      "outputs": [],
      "source": [
        "DATAPATH = 'drive/MyDrive/EI_web_data/Data'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_GHT375MuAMY"
      },
      "source": [
        "###Save and load data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "8CS8gtUbveQK"
      },
      "outputs": [],
      "source": [
        "# Save and Load your data in Pickle format\n",
        "\n",
        "def save_data(savepath, file_name, obj):\n",
        "    with open(os.path.join(savepath, file_name), 'wb') as file:\n",
        "      pickle.dump(obj, file)\n",
        "\n",
        "def load_data(savepath, file_name):\n",
        "    with open(os.path.join(savepath, file_name),'rb') as file:\n",
        "      return pickle.load(file)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UVggTxw0i_JT"
      },
      "source": [
        "## Extraction the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "oKKTrOCQi_JT"
      },
      "outputs": [],
      "source": [
        "def remove_tags(text:str)->str:\n",
        "  '''retire les balises html du texte'''\n",
        "  soup = BeautifulSoup(text, 'html.parser')\n",
        "\n",
        "  # Supprimer toutes les balises de script et de style\n",
        "  for script in soup(['script', 'style']):\n",
        "    script.extract()\n",
        "\n",
        "  # Obtenir le texte propre sans balises\n",
        "  texte_propre = soup.get_text()\n",
        "  \n",
        "  # Supprimer les espaces supplémentaires et les sauts de ligne\n",
        "  texte_propre = re.sub(r'\\s+', ' ', texte_propre)\n",
        "\n",
        "  return texte_propre\n",
        "\n",
        "def extract_tokens(text:str)->list:\n",
        "  '''récupère (tous) les mots de chaque phrase'''\n",
        "  tokens=re.findall(r'\\w+', text)     \n",
        "  return [token.lower() for token in tokens]\n",
        "\n",
        "def lemmatize(tokens:list)->list:\n",
        "  '''lemmatise tous les mots de la liste'''\n",
        "  wnl = WordNetLemmatizer()\n",
        "  return [wnl.lemmatize(token) for token in tokens]\n",
        "\n",
        "def remove_stopwords(word_list):\n",
        "  '''retire tous les stopwords de la liste'''\n",
        "  return [word for word in word_list if word not in stopwords.words('english')]\n",
        "\n",
        "\n",
        "def extract_data(datapath):\n",
        "    df=pd.read_xml(os.path.join(datapath, 'Posts.xml'), parser=\"etree\", encoding=\"utf8\")\n",
        "    df['CleanBody'] = df['Body'].fillna('').apply(remove_tags)\n",
        "    df['Tokens'] = df['CleanBody'].apply(extract_tokens)\n",
        "    df['Words']= df['Tokens'].apply(lemmatize)\n",
        "    df['MeaningfullWords'] = df['Words'].apply(remove_stopwords)\n",
        "\n",
        "    return df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WKyNkcZTzsz2"
      },
      "source": [
        "The firt time you execute the code, uncomment to extract data then save it (it may take a few minutes). The next times you can just load the dataframe."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "neDTh1cii_JU"
      },
      "outputs": [],
      "source": [
        "#df = extract_data(datapath=DATAPATH) \n",
        "#save_data(DATAPATH, 'df.pkl', df)\n",
        "df=load_data(DATAPATH, 'df.pkl')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pv1LW7pgi_JU"
      },
      "source": [
        "## Indexation data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "QgfhMclXNtko"
      },
      "outputs": [],
      "source": [
        "def index_data(df:pd.DataFrame)-> set:\n",
        "  ''' renvoie un dictionnaire de la forme \n",
        "  dic={mot:{id:f_id}}'''\n",
        "\n",
        "  dic={}\n",
        "  for rang in df.index:\n",
        "    Words = df.loc[rang, 'Words']\n",
        "    id = df.loc[rang,'Id']\n",
        "    for word in Words:\n",
        "      if word in dic.keys(): #si le mot est déjà apparu dans le corpus\n",
        "        if id in dic[word].keys(): #si le mot est déjà apparu dans ce document\n",
        "          dic[word][id]+=1\n",
        "        else:\n",
        "          dic[word][id]=1 #première occurence du mot dans ce document\n",
        "      else:#première occurence du mot dans le corpus\n",
        "        dic[word]={id: 1}\n",
        "\n",
        "  return dic"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "iqqHhitMNuRm"
      },
      "outputs": [],
      "source": [
        "#inverted_index=index_data(df)\n",
        "#save_data(DATAPATH, 'inverted_index.pkl', inverted_index)\n",
        "inverted_index=load_data(DATAPATH, 'inverted_index.pkl')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BFX6mpI-i_JV"
      },
      "source": [
        "## Search Method"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "23V_yU5zy4GJ"
      },
      "outputs": [],
      "source": [
        "MODEL_ST = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "#embeddings = MODEL_ST.encode(df.CleanBody.values, normalize_embeddings=True)\n",
        "#save_data(DATAPATH, 'embeddings.pkl', embeddings)\n",
        "embeddings=load_data(DATAPATH, 'embeddings.pkl')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "SIX40Jlti_JV"
      },
      "outputs": [],
      "source": [
        "def similarity_matrix(query, df=df, embeddings=embeddings, MODEL_ST=MODEL_ST):\n",
        "  encoded_query = MODEL_ST.encode([query], normalize_embeddings=True)\n",
        "  matrix=cosine_similarity(encoded_query, embeddings)\n",
        "  return(matrix)\n",
        "\n",
        "\n",
        "def BM25(query, df=df, inverted_index=inverted_index, k1=1.5, b=0.75):\n",
        "  '''retourne une copy de la dataframe avec une colonne 'Queryscore' contenant le score BM25 pour la requête'''\n",
        "  #extraction des mots de la requête\n",
        "  processed_query=lemmatize(extract_tokens(query))\n",
        "\n",
        "  #création d'une copie de la dataframe\n",
        "  df_copy=df.copy()\n",
        "\n",
        "  #ajout d'une colonne longueur du document\n",
        "  df_copy['Lenght']=df_copy['Words'].apply(lambda x : len(x))\n",
        "\n",
        "  N=len(df_copy) #nombre de docs dans la collection\n",
        "  avgdl=df_copy['Lenght'].mean() #longueur moyenne des docs\n",
        "\n",
        "  #calcul du score de chaque document\n",
        "  scores=[]\n",
        "  for rang in df_copy.index:\n",
        "    doc_id=df_copy.loc[rang,'Id']\n",
        "    lenght=df_copy.loc[rang,'Lenght']\n",
        "    s=0\n",
        "\n",
        "    for terme in processed_query:\n",
        "      if terme not in inverted_index : \n",
        "        s+=0 #le terme n'apparait ni dans le doc ni même dans le corpus --> contribution nulle au score \n",
        "      else :\n",
        "        n=len(inverted_index[terme]) # nombre de documents contenants le terme\n",
        "        \n",
        "        IDF=math.log((N-n+0.5)/(n+0.5))\n",
        "        if doc_id in inverted_index[terme]: freq=inverted_index[terme][doc_id]\n",
        "        else: freq=0\n",
        "        s+=IDF*freq*(k1+1)/(freq+k1*(1-b+b*lenght/avgdl))\n",
        "    \n",
        "    scores.append(s)\n",
        "\n",
        "  #ajout d'une colonne 'Queryscore' à la copie de la dataframe\n",
        "  df_copy['QueryScore']=scores\n",
        "\n",
        "  return scores\n",
        "\n",
        "\n",
        "def scored_df(query, df=df, inverted_index=inverted_index, k1=1.5, b=0.75, embeddings=embeddings, MODEL_ST=MODEL_ST):\n",
        "  ''' renvoie une copie de la dataframe munie des colonnes 'ScoreBM25' et 'CosineSimilarity' '''\n",
        "  df_copy=df.copy()\n",
        "  df_copy['ScoreBM25']=BM25(query, df, inverted_index, k1, b)\n",
        "  df_copy['CosineSimilarity'] = similarity_matrix(query, df, embeddings, MODEL_ST)[0]\n",
        "  return df_copy\n",
        "\n",
        "#à la fin de scored_query, on obtient une df avec deux colonnes contenant les score BM25 et la mesure similarité\n",
        "\n",
        "def search(query, df=df, inverted_index=inverted_index, k1=1.5, b=0.75, embeddings=embeddings, MODEL_ST=MODEL_ST):\n",
        "  \n",
        "  return"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "5AFL4OGgNEdz",
        "outputId": "6228a033-5fcb-4d02-92be-4fd2178c278b"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-ba3aec56-f670-4a07-bf43-36503cadb605\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>PostTypeId</th>\n",
              "      <th>CreationDate</th>\n",
              "      <th>Score</th>\n",
              "      <th>ViewCount</th>\n",
              "      <th>Body</th>\n",
              "      <th>OwnerUserId</th>\n",
              "      <th>LastActivityDate</th>\n",
              "      <th>Title</th>\n",
              "      <th>Tags</th>\n",
              "      <th>...</th>\n",
              "      <th>OwnerDisplayName</th>\n",
              "      <th>CommunityOwnedDate</th>\n",
              "      <th>LastEditorDisplayName</th>\n",
              "      <th>FavoriteCount</th>\n",
              "      <th>CleanBody</th>\n",
              "      <th>Tokens</th>\n",
              "      <th>Words</th>\n",
              "      <th>MeaningfullWords</th>\n",
              "      <th>ScoreBM25</th>\n",
              "      <th>CosineSimilarity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>2014-05-13T23:58:30.457</td>\n",
              "      <td>9</td>\n",
              "      <td>898.0</td>\n",
              "      <td>&lt;p&gt;I've always been interested in machine lear...</td>\n",
              "      <td>5.0</td>\n",
              "      <td>2014-05-14T00:36:31.077</td>\n",
              "      <td>How can I do simple machine learning without h...</td>\n",
              "      <td>&lt;machine-learning&gt;</td>\n",
              "      <td>...</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>NaN</td>\n",
              "      <td>I've always been interested in machine learnin...</td>\n",
              "      <td>[i, ve, always, been, interested, in, machine,...</td>\n",
              "      <td>[i, ve, always, been, interested, in, machine,...</td>\n",
              "      <td>[always, interested, machine, learning, figure...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.200056</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>2014-05-14T00:11:06.457</td>\n",
              "      <td>4</td>\n",
              "      <td>478.0</td>\n",
              "      <td>&lt;p&gt;As a researcher and instructor, I'm looking...</td>\n",
              "      <td>36.0</td>\n",
              "      <td>2014-05-16T13:45:00.237</td>\n",
              "      <td>What open-source books (or other materials) pr...</td>\n",
              "      <td>&lt;education&gt;&lt;open-source&gt;</td>\n",
              "      <td>...</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>NaN</td>\n",
              "      <td>As a researcher and instructor, I'm looking fo...</td>\n",
              "      <td>[as, a, researcher, and, instructor, i, m, loo...</td>\n",
              "      <td>[a, a, researcher, and, instructor, i, m, look...</td>\n",
              "      <td>[researcher, instructor, looking, open, source...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.073826</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>9</td>\n",
              "      <td>2</td>\n",
              "      <td>2014-05-14T00:36:31.077</td>\n",
              "      <td>5</td>\n",
              "      <td>NaN</td>\n",
              "      <td>&lt;p&gt;Not sure if this fits the scope of this SE,...</td>\n",
              "      <td>51.0</td>\n",
              "      <td>2014-05-14T00:36:31.077</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>...</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Not sure if this fits the scope of this SE, bu...</td>\n",
              "      <td>[not, sure, if, this, fits, the, scope, of, th...</td>\n",
              "      <td>[not, sure, if, this, fit, the, scope, of, thi...</td>\n",
              "      <td>[sure, fit, scope, se, stab, answer, anyway, a...</td>\n",
              "      <td>-0.851537</td>\n",
              "      <td>0.193558</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>10</td>\n",
              "      <td>2</td>\n",
              "      <td>2014-05-14T00:53:43.273</td>\n",
              "      <td>13</td>\n",
              "      <td>NaN</td>\n",
              "      <td>&lt;p&gt;One book that's freely available is \"The El...</td>\n",
              "      <td>22.0</td>\n",
              "      <td>2014-05-14T00:53:43.273</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>...</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>NaN</td>\n",
              "      <td>One book that's freely available is \"The Eleme...</td>\n",
              "      <td>[one, book, that, s, freely, available, is, th...</td>\n",
              "      <td>[one, book, that, s, freely, available, is, th...</td>\n",
              "      <td>[one, book, freely, available, element, statis...</td>\n",
              "      <td>-2.265948</td>\n",
              "      <td>0.331188</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>14</td>\n",
              "      <td>1</td>\n",
              "      <td>2014-05-14T01:25:59.677</td>\n",
              "      <td>26</td>\n",
              "      <td>1901.0</td>\n",
              "      <td>&lt;p&gt;I am sure data science as will be discussed...</td>\n",
              "      <td>66.0</td>\n",
              "      <td>2020-08-16T13:01:33.543</td>\n",
              "      <td>Is Data Science the Same as Data Mining?</td>\n",
              "      <td>&lt;data-mining&gt;&lt;definitions&gt;</td>\n",
              "      <td>...</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>NaN</td>\n",
              "      <td>I am sure data science as will be discussed in...</td>\n",
              "      <td>[i, am, sure, data, science, as, will, be, dis...</td>\n",
              "      <td>[i, am, sure, data, science, a, will, be, disc...</td>\n",
              "      <td>[sure, data, science, discussed, forum, ha, se...</td>\n",
              "      <td>-0.668133</td>\n",
              "      <td>0.087813</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75722</th>\n",
              "      <td>119962</td>\n",
              "      <td>1</td>\n",
              "      <td>2023-03-04T20:06:06.820</td>\n",
              "      <td>0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>&lt;p&gt;I am implementing a neural network of arbit...</td>\n",
              "      <td>147597.0</td>\n",
              "      <td>2023-03-04T20:22:12.523</td>\n",
              "      <td>Back Propagation on arbitrary depth network wi...</td>\n",
              "      <td>&lt;neural-network&gt;&lt;backpropagation&gt;</td>\n",
              "      <td>...</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>NaN</td>\n",
              "      <td>I am implementing a neural network of arbitrar...</td>\n",
              "      <td>[i, am, implementing, a, neural, network, of, ...</td>\n",
              "      <td>[i, am, implementing, a, neural, network, of, ...</td>\n",
              "      <td>[implementing, neural, network, arbitrary, dep...</td>\n",
              "      <td>2.314880</td>\n",
              "      <td>0.230572</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75723</th>\n",
              "      <td>119963</td>\n",
              "      <td>1</td>\n",
              "      <td>2023-03-04T20:12:19.677</td>\n",
              "      <td>0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>&lt;p&gt;I am using KNN for a regression task&lt;/p&gt;\\n&lt;...</td>\n",
              "      <td>147598.0</td>\n",
              "      <td>2023-03-04T20:12:19.677</td>\n",
              "      <td>Evaluation parameter in knn</td>\n",
              "      <td>&lt;regression&gt;&lt;k-nn&gt;</td>\n",
              "      <td>...</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>NaN</td>\n",
              "      <td>I am using KNN for a regression task It's like...</td>\n",
              "      <td>[i, am, using, knn, for, a, regression, task, ...</td>\n",
              "      <td>[i, am, using, knn, for, a, regression, task, ...</td>\n",
              "      <td>[using, knn, regression, task, like, 1, normal...</td>\n",
              "      <td>-2.196023</td>\n",
              "      <td>-0.013185</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75724</th>\n",
              "      <td>119964</td>\n",
              "      <td>1</td>\n",
              "      <td>2023-03-05T00:14:12.597</td>\n",
              "      <td>0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>&lt;p&gt;I have developed a small encoding algorithm...</td>\n",
              "      <td>44581.0</td>\n",
              "      <td>2023-03-05T00:14:12.597</td>\n",
              "      <td>Can I use zero-padded input and output layers ...</td>\n",
              "      <td>&lt;deep-learning&gt;&lt;convolutional-neural-network&gt;</td>\n",
              "      <td>...</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>NaN</td>\n",
              "      <td>I have developed a small encoding algorithm th...</td>\n",
              "      <td>[i, have, developed, a, small, encoding, algor...</td>\n",
              "      <td>[i, have, developed, a, small, encoding, algor...</td>\n",
              "      <td>[developed, small, encoding, algorithm, accept...</td>\n",
              "      <td>-1.874446</td>\n",
              "      <td>0.124191</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75725</th>\n",
              "      <td>119965</td>\n",
              "      <td>1</td>\n",
              "      <td>2023-03-05T00:43:12.213</td>\n",
              "      <td>0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>&lt;p&gt;To my understanding, optimizing a model wit...</td>\n",
              "      <td>84437.0</td>\n",
              "      <td>2023-03-05T00:43:12.213</td>\n",
              "      <td>Why does cross validation and hyperparameter t...</td>\n",
              "      <td>&lt;cross-validation&gt;&lt;hyperparameter-tuning&gt;</td>\n",
              "      <td>...</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>NaN</td>\n",
              "      <td>To my understanding, optimizing a model with k...</td>\n",
              "      <td>[to, my, understanding, optimizing, a, model, ...</td>\n",
              "      <td>[to, my, understanding, optimizing, a, model, ...</td>\n",
              "      <td>[understanding, optimizing, model, k, fold, cr...</td>\n",
              "      <td>-2.368447</td>\n",
              "      <td>0.106993</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75726</th>\n",
              "      <td>119966</td>\n",
              "      <td>1</td>\n",
              "      <td>2023-03-05T03:10:27.593</td>\n",
              "      <td>0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>&lt;p&gt;I'm working with a dataset of cars, contain...</td>\n",
              "      <td>147605.0</td>\n",
              "      <td>2023-03-05T03:10:27.593</td>\n",
              "      <td>High metrics value (MAE, MSE, RMSE)</td>\n",
              "      <td>&lt;python&gt;&lt;pandas&gt;&lt;machine-learning-model&gt;&lt;linea...</td>\n",
              "      <td>...</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>NaN</td>\n",
              "      <td>I'm working with a dataset of cars, containing...</td>\n",
              "      <td>[i, m, working, with, a, dataset, of, cars, co...</td>\n",
              "      <td>[i, m, working, with, a, dataset, of, car, con...</td>\n",
              "      <td>[working, dataset, car, containing, 10k, row, ...</td>\n",
              "      <td>-1.609566</td>\n",
              "      <td>0.031840</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>75727 rows × 28 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ba3aec56-f670-4a07-bf43-36503cadb605')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ba3aec56-f670-4a07-bf43-36503cadb605 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ba3aec56-f670-4a07-bf43-36503cadb605');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "           Id  PostTypeId             CreationDate  Score  ViewCount  \\\n",
              "0           5           1  2014-05-13T23:58:30.457      9      898.0   \n",
              "1           7           1  2014-05-14T00:11:06.457      4      478.0   \n",
              "2           9           2  2014-05-14T00:36:31.077      5        NaN   \n",
              "3          10           2  2014-05-14T00:53:43.273     13        NaN   \n",
              "4          14           1  2014-05-14T01:25:59.677     26     1901.0   \n",
              "...       ...         ...                      ...    ...        ...   \n",
              "75722  119962           1  2023-03-04T20:06:06.820      0        8.0   \n",
              "75723  119963           1  2023-03-04T20:12:19.677      0       10.0   \n",
              "75724  119964           1  2023-03-05T00:14:12.597      0        7.0   \n",
              "75725  119965           1  2023-03-05T00:43:12.213      0        5.0   \n",
              "75726  119966           1  2023-03-05T03:10:27.593      0        2.0   \n",
              "\n",
              "                                                    Body  OwnerUserId  \\\n",
              "0      <p>I've always been interested in machine lear...          5.0   \n",
              "1      <p>As a researcher and instructor, I'm looking...         36.0   \n",
              "2      <p>Not sure if this fits the scope of this SE,...         51.0   \n",
              "3      <p>One book that's freely available is \"The El...         22.0   \n",
              "4      <p>I am sure data science as will be discussed...         66.0   \n",
              "...                                                  ...          ...   \n",
              "75722  <p>I am implementing a neural network of arbit...     147597.0   \n",
              "75723  <p>I am using KNN for a regression task</p>\\n<...     147598.0   \n",
              "75724  <p>I have developed a small encoding algorithm...      44581.0   \n",
              "75725  <p>To my understanding, optimizing a model wit...      84437.0   \n",
              "75726  <p>I'm working with a dataset of cars, contain...     147605.0   \n",
              "\n",
              "              LastActivityDate  \\\n",
              "0      2014-05-14T00:36:31.077   \n",
              "1      2014-05-16T13:45:00.237   \n",
              "2      2014-05-14T00:36:31.077   \n",
              "3      2014-05-14T00:53:43.273   \n",
              "4      2020-08-16T13:01:33.543   \n",
              "...                        ...   \n",
              "75722  2023-03-04T20:22:12.523   \n",
              "75723  2023-03-04T20:12:19.677   \n",
              "75724  2023-03-05T00:14:12.597   \n",
              "75725  2023-03-05T00:43:12.213   \n",
              "75726  2023-03-05T03:10:27.593   \n",
              "\n",
              "                                                   Title  \\\n",
              "0      How can I do simple machine learning without h...   \n",
              "1      What open-source books (or other materials) pr...   \n",
              "2                                                   None   \n",
              "3                                                   None   \n",
              "4               Is Data Science the Same as Data Mining?   \n",
              "...                                                  ...   \n",
              "75722  Back Propagation on arbitrary depth network wi...   \n",
              "75723                        Evaluation parameter in knn   \n",
              "75724  Can I use zero-padded input and output layers ...   \n",
              "75725  Why does cross validation and hyperparameter t...   \n",
              "75726                High metrics value (MAE, MSE, RMSE)   \n",
              "\n",
              "                                                    Tags  ...  \\\n",
              "0                                     <machine-learning>  ...   \n",
              "1                               <education><open-source>  ...   \n",
              "2                                                   None  ...   \n",
              "3                                                   None  ...   \n",
              "4                             <data-mining><definitions>  ...   \n",
              "...                                                  ...  ...   \n",
              "75722                  <neural-network><backpropagation>  ...   \n",
              "75723                                 <regression><k-nn>  ...   \n",
              "75724      <deep-learning><convolutional-neural-network>  ...   \n",
              "75725          <cross-validation><hyperparameter-tuning>  ...   \n",
              "75726  <python><pandas><machine-learning-model><linea...  ...   \n",
              "\n",
              "       OwnerDisplayName  CommunityOwnedDate LastEditorDisplayName  \\\n",
              "0                  None                None                  None   \n",
              "1                  None                None                  None   \n",
              "2                  None                None                  None   \n",
              "3                  None                None                  None   \n",
              "4                  None                None                  None   \n",
              "...                 ...                 ...                   ...   \n",
              "75722              None                None                  None   \n",
              "75723              None                None                  None   \n",
              "75724              None                None                  None   \n",
              "75725              None                None                  None   \n",
              "75726              None                None                  None   \n",
              "\n",
              "      FavoriteCount                                          CleanBody  \\\n",
              "0               NaN  I've always been interested in machine learnin...   \n",
              "1               NaN  As a researcher and instructor, I'm looking fo...   \n",
              "2               NaN  Not sure if this fits the scope of this SE, bu...   \n",
              "3               NaN  One book that's freely available is \"The Eleme...   \n",
              "4               NaN  I am sure data science as will be discussed in...   \n",
              "...             ...                                                ...   \n",
              "75722           NaN  I am implementing a neural network of arbitrar...   \n",
              "75723           NaN  I am using KNN for a regression task It's like...   \n",
              "75724           NaN  I have developed a small encoding algorithm th...   \n",
              "75725           NaN  To my understanding, optimizing a model with k...   \n",
              "75726           NaN  I'm working with a dataset of cars, containing...   \n",
              "\n",
              "                                                  Tokens  \\\n",
              "0      [i, ve, always, been, interested, in, machine,...   \n",
              "1      [as, a, researcher, and, instructor, i, m, loo...   \n",
              "2      [not, sure, if, this, fits, the, scope, of, th...   \n",
              "3      [one, book, that, s, freely, available, is, th...   \n",
              "4      [i, am, sure, data, science, as, will, be, dis...   \n",
              "...                                                  ...   \n",
              "75722  [i, am, implementing, a, neural, network, of, ...   \n",
              "75723  [i, am, using, knn, for, a, regression, task, ...   \n",
              "75724  [i, have, developed, a, small, encoding, algor...   \n",
              "75725  [to, my, understanding, optimizing, a, model, ...   \n",
              "75726  [i, m, working, with, a, dataset, of, cars, co...   \n",
              "\n",
              "                                                   Words  \\\n",
              "0      [i, ve, always, been, interested, in, machine,...   \n",
              "1      [a, a, researcher, and, instructor, i, m, look...   \n",
              "2      [not, sure, if, this, fit, the, scope, of, thi...   \n",
              "3      [one, book, that, s, freely, available, is, th...   \n",
              "4      [i, am, sure, data, science, a, will, be, disc...   \n",
              "...                                                  ...   \n",
              "75722  [i, am, implementing, a, neural, network, of, ...   \n",
              "75723  [i, am, using, knn, for, a, regression, task, ...   \n",
              "75724  [i, have, developed, a, small, encoding, algor...   \n",
              "75725  [to, my, understanding, optimizing, a, model, ...   \n",
              "75726  [i, m, working, with, a, dataset, of, car, con...   \n",
              "\n",
              "                                        MeaningfullWords ScoreBM25  \\\n",
              "0      [always, interested, machine, learning, figure...  0.000000   \n",
              "1      [researcher, instructor, looking, open, source...  0.000000   \n",
              "2      [sure, fit, scope, se, stab, answer, anyway, a... -0.851537   \n",
              "3      [one, book, freely, available, element, statis... -2.265948   \n",
              "4      [sure, data, science, discussed, forum, ha, se... -0.668133   \n",
              "...                                                  ...       ...   \n",
              "75722  [implementing, neural, network, arbitrary, dep...  2.314880   \n",
              "75723  [using, knn, regression, task, like, 1, normal... -2.196023   \n",
              "75724  [developed, small, encoding, algorithm, accept... -1.874446   \n",
              "75725  [understanding, optimizing, model, k, fold, cr... -2.368447   \n",
              "75726  [working, dataset, car, containing, 10k, row, ... -1.609566   \n",
              "\n",
              "      CosineSimilarity  \n",
              "0             0.200056  \n",
              "1             0.073826  \n",
              "2             0.193558  \n",
              "3             0.331188  \n",
              "4             0.087813  \n",
              "...                ...  \n",
              "75722         0.230572  \n",
              "75723        -0.013185  \n",
              "75724         0.124191  \n",
              "75725         0.106993  \n",
              "75726         0.031840  \n",
              "\n",
              "[75727 rows x 28 columns]"
            ]
          },
          "execution_count": 57,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "query='what is stochastic gradient descent ?'\n",
        "scored_df(query)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6_9CmVMzi_JW"
      },
      "source": [
        "## Ranking"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WQr_WUP6i_JW"
      },
      "outputs": [],
      "source": [
        "def rank_search(results, top=5):\n",
        "    # TODO\n",
        "\n",
        "    return"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BqFkUY_Wi_JW"
      },
      "source": [
        "## Visualising Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "105whCkRi_JW"
      },
      "outputs": [],
      "source": [
        "def visualize_output():\n",
        "    # TODO\n",
        "    \n",
        "    return"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WHpexXoni_JX"
      },
      "source": [
        "## Querying"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E3EZ4d0Li_JX"
      },
      "outputs": [],
      "source": [
        "def make_query(natural_query):\n",
        "    # TODO\n",
        "\n",
        "    return"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9PYv7zMJi_JX"
      },
      "source": [
        "## Scoring"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y43l3P99i_JX"
      },
      "outputs": [],
      "source": [
        "# Pas sûr de garder cette partie"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sK43W4vGi_JY"
      },
      "source": [
        "## Testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2JtRNiJ1i_JY"
      },
      "outputs": [],
      "source": [
        "# TODO"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
