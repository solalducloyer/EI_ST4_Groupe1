{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xycip-y7MmUq"
      },
      "source": [
        "# DAY 3: Student version"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gnCKD6NtjZno"
      },
      "source": [
        "**Machine Learning NLP**\n",
        "\n",
        "The goal of this session is to improve the search engine using NLP features.\n",
        "\n",
        "This notebook guides you through different techniques to explore. It is expected of you to be inventive and improve the techniques introduced. \n",
        "\n",
        "First, let's import the useful packages and load the data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tS0Nv3gMZw7D"
      },
      "source": [
        "## Installs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "id": "BU8SMVS4Zu0w"
      },
      "outputs": [],
      "source": [
        "! pip install sentence-transformers --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RNiZEBzfu3DA",
        "outputId": "17ae59a9-9dc7-4a0b-d7b7-534b782529e7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (4.11.2)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4) (2.4.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install beautifulsoup4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TBamWPKlkZs0"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "50KuGjmPjquG",
        "outputId": "7fb84995-5f9d-46f5-b406-57e67dd50cb3"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import re\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.decomposition import LatentDirichletAllocation\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from scipy.sparse import find\n",
        "\n",
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "\n",
        "from nltk import word_tokenize          \n",
        "from nltk.stem import WordNetLemmatizer "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bVl7AEcBkgyz"
      },
      "source": [
        "## Load Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aVb0xZIvkevD",
        "outputId": "e36da7b4-e9b6-4976-ebb7-14dd1c9c3a87"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# Only if you use Colab\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import os\n",
        "\n",
        "# TODO:\n",
        "DATA_PATH = 'drive/MyDrive/EI_web_data/Data' "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {
        "id": "YBtfx_3RYSs9"
      },
      "outputs": [],
      "source": [
        "posts = pd.read_xml(os.path.join(DATA_PATH, 'Posts.xml'), parser=\"etree\", encoding=\"utf8\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2q_ryLonxLYe"
      },
      "source": [
        "## Data Cleaning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cnOIzOY4e5Xh"
      },
      "source": [
        "Implement a function to clean the posts. \n",
        "\n",
        "You can reuse what you have used in the Day 2 notebook or improve it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "metadata": {
        "id": "9e-XxHMAkmEu"
      },
      "outputs": [],
      "source": [
        "def clean_post(text:str)->str:\n",
        "  if type(text)==str:\n",
        "    soup = BeautifulSoup(text, 'html.parser')\n",
        "\n",
        "    # Supprimer toutes les balises de script et de style\n",
        "    for script in soup(['script', 'style']):\n",
        "      script.extract()\n",
        "\n",
        "    # Obtenir le texte propre sans balises\n",
        "    texte_propre = soup.get_text()\n",
        "    \n",
        "    # Supprimer les espaces supplémentaires et les sauts de ligne\n",
        "    texte_propre = re.sub(r'\\s+', ' ', texte_propre)\n",
        "\n",
        "    return texte_propre"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yv_n2e5Y1a04",
        "outputId": "3f61b9b4-c931-401f-9205-7d4435182c9f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-103-ad5f83adcb86>:3: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
            "  soup = BeautifulSoup(text, 'html.parser')\n"
          ]
        }
      ],
      "source": [
        "posts['cleaned_body'] = posts.Body.apply(clean_post)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "metadata": {
        "id": "PDmN6Lg5yzuS"
      },
      "outputs": [],
      "source": [
        "# Supprimer les lignes où 'clean_body' n'est pas une chaîne de caractères\n",
        "posts = posts.drop(posts[~posts['cleaned_body'].apply(lambda x: isinstance(x, str))].index)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 159,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3_pISi2SBuVR",
        "outputId": "234f92bb-5cb2-45d2-8ce0-d959610b6f28"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Index(['Id', 'PostTypeId', 'CreationDate', 'Score', 'ViewCount', 'Body',\n",
              "       'OwnerUserId', 'LastActivityDate', 'Title', 'Tags', 'AnswerCount',\n",
              "       'CommentCount', 'ClosedDate', 'ContentLicense', 'AcceptedAnswerId',\n",
              "       'LastEditorUserId', 'LastEditDate', 'ParentId', 'OwnerDisplayName',\n",
              "       'CommunityOwnedDate', 'LastEditorDisplayName', 'FavoriteCount',\n",
              "       'cleaned_body'],\n",
              "      dtype='object')"
            ]
          },
          "execution_count": 159,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "posts.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 109,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "oflWpT8pv1MI",
        "outputId": "f5db0249-12c9-413d-fc3a-059d7bb00ffd"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-3768f831-a51f-41d0-99d7-df8b1979ba69\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>PostTypeId</th>\n",
              "      <th>CreationDate</th>\n",
              "      <th>Score</th>\n",
              "      <th>ViewCount</th>\n",
              "      <th>Body</th>\n",
              "      <th>OwnerUserId</th>\n",
              "      <th>LastActivityDate</th>\n",
              "      <th>Title</th>\n",
              "      <th>Tags</th>\n",
              "      <th>...</th>\n",
              "      <th>ContentLicense</th>\n",
              "      <th>AcceptedAnswerId</th>\n",
              "      <th>LastEditorUserId</th>\n",
              "      <th>LastEditDate</th>\n",
              "      <th>ParentId</th>\n",
              "      <th>OwnerDisplayName</th>\n",
              "      <th>CommunityOwnedDate</th>\n",
              "      <th>LastEditorDisplayName</th>\n",
              "      <th>FavoriteCount</th>\n",
              "      <th>cleaned_body</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>2014-05-13T23:58:30.457</td>\n",
              "      <td>9</td>\n",
              "      <td>898.0</td>\n",
              "      <td>&lt;p&gt;I've always been interested in machine lear...</td>\n",
              "      <td>5.0</td>\n",
              "      <td>2014-05-14T00:36:31.077</td>\n",
              "      <td>How can I do simple machine learning without h...</td>\n",
              "      <td>&lt;machine-learning&gt;</td>\n",
              "      <td>...</td>\n",
              "      <td>CC BY-SA 3.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>None</td>\n",
              "      <td>NaN</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>NaN</td>\n",
              "      <td>I've always been interested in machine learnin...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>2014-05-14T00:11:06.457</td>\n",
              "      <td>4</td>\n",
              "      <td>478.0</td>\n",
              "      <td>&lt;p&gt;As a researcher and instructor, I'm looking...</td>\n",
              "      <td>36.0</td>\n",
              "      <td>2014-05-16T13:45:00.237</td>\n",
              "      <td>What open-source books (or other materials) pr...</td>\n",
              "      <td>&lt;education&gt;&lt;open-source&gt;</td>\n",
              "      <td>...</td>\n",
              "      <td>CC BY-SA 3.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>97.0</td>\n",
              "      <td>2014-05-16T13:45:00.237</td>\n",
              "      <td>NaN</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>NaN</td>\n",
              "      <td>As a researcher and instructor, I'm looking fo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>9</td>\n",
              "      <td>2</td>\n",
              "      <td>2014-05-14T00:36:31.077</td>\n",
              "      <td>5</td>\n",
              "      <td>NaN</td>\n",
              "      <td>&lt;p&gt;Not sure if this fits the scope of this SE,...</td>\n",
              "      <td>51.0</td>\n",
              "      <td>2014-05-14T00:36:31.077</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>...</td>\n",
              "      <td>CC BY-SA 3.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>None</td>\n",
              "      <td>5.0</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Not sure if this fits the scope of this SE, bu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>10</td>\n",
              "      <td>2</td>\n",
              "      <td>2014-05-14T00:53:43.273</td>\n",
              "      <td>13</td>\n",
              "      <td>NaN</td>\n",
              "      <td>&lt;p&gt;One book that's freely available is \"The El...</td>\n",
              "      <td>22.0</td>\n",
              "      <td>2014-05-14T00:53:43.273</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>...</td>\n",
              "      <td>CC BY-SA 3.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>None</td>\n",
              "      <td>7.0</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>NaN</td>\n",
              "      <td>One book that's freely available is \"The Eleme...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>14</td>\n",
              "      <td>1</td>\n",
              "      <td>2014-05-14T01:25:59.677</td>\n",
              "      <td>26</td>\n",
              "      <td>1901.0</td>\n",
              "      <td>&lt;p&gt;I am sure data science as will be discussed...</td>\n",
              "      <td>66.0</td>\n",
              "      <td>2020-08-16T13:01:33.543</td>\n",
              "      <td>Is Data Science the Same as Data Mining?</td>\n",
              "      <td>&lt;data-mining&gt;&lt;definitions&gt;</td>\n",
              "      <td>...</td>\n",
              "      <td>CC BY-SA 3.0</td>\n",
              "      <td>29.0</td>\n",
              "      <td>322.0</td>\n",
              "      <td>2014-06-17T16:17:20.473</td>\n",
              "      <td>NaN</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>NaN</td>\n",
              "      <td>I am sure data science as will be discussed in...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75722</th>\n",
              "      <td>119962</td>\n",
              "      <td>1</td>\n",
              "      <td>2023-03-04T20:06:06.820</td>\n",
              "      <td>0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>&lt;p&gt;I am implementing a neural network of arbit...</td>\n",
              "      <td>147597.0</td>\n",
              "      <td>2023-03-04T20:22:12.523</td>\n",
              "      <td>Back Propagation on arbitrary depth network wi...</td>\n",
              "      <td>&lt;neural-network&gt;&lt;backpropagation&gt;</td>\n",
              "      <td>...</td>\n",
              "      <td>CC BY-SA 4.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>147597.0</td>\n",
              "      <td>2023-03-04T20:22:12.523</td>\n",
              "      <td>NaN</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>NaN</td>\n",
              "      <td>I am implementing a neural network of arbitrar...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75723</th>\n",
              "      <td>119963</td>\n",
              "      <td>1</td>\n",
              "      <td>2023-03-04T20:12:19.677</td>\n",
              "      <td>0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>&lt;p&gt;I am using KNN for a regression task&lt;/p&gt;\\n&lt;...</td>\n",
              "      <td>147598.0</td>\n",
              "      <td>2023-03-04T20:12:19.677</td>\n",
              "      <td>Evaluation parameter in knn</td>\n",
              "      <td>&lt;regression&gt;&lt;k-nn&gt;</td>\n",
              "      <td>...</td>\n",
              "      <td>CC BY-SA 4.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>None</td>\n",
              "      <td>NaN</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>NaN</td>\n",
              "      <td>I am using KNN for a regression task It's like...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75724</th>\n",
              "      <td>119964</td>\n",
              "      <td>1</td>\n",
              "      <td>2023-03-05T00:14:12.597</td>\n",
              "      <td>0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>&lt;p&gt;I have developed a small encoding algorithm...</td>\n",
              "      <td>44581.0</td>\n",
              "      <td>2023-03-05T00:14:12.597</td>\n",
              "      <td>Can I use zero-padded input and output layers ...</td>\n",
              "      <td>&lt;deep-learning&gt;&lt;convolutional-neural-network&gt;</td>\n",
              "      <td>...</td>\n",
              "      <td>CC BY-SA 4.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>None</td>\n",
              "      <td>NaN</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>NaN</td>\n",
              "      <td>I have developed a small encoding algorithm th...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75725</th>\n",
              "      <td>119965</td>\n",
              "      <td>1</td>\n",
              "      <td>2023-03-05T00:43:12.213</td>\n",
              "      <td>0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>&lt;p&gt;To my understanding, optimizing a model wit...</td>\n",
              "      <td>84437.0</td>\n",
              "      <td>2023-03-05T00:43:12.213</td>\n",
              "      <td>Why does cross validation and hyperparameter t...</td>\n",
              "      <td>&lt;cross-validation&gt;&lt;hyperparameter-tuning&gt;</td>\n",
              "      <td>...</td>\n",
              "      <td>CC BY-SA 4.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>None</td>\n",
              "      <td>NaN</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>NaN</td>\n",
              "      <td>To my understanding, optimizing a model with k...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75726</th>\n",
              "      <td>119966</td>\n",
              "      <td>1</td>\n",
              "      <td>2023-03-05T03:10:27.593</td>\n",
              "      <td>0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>&lt;p&gt;I'm working with a dataset of cars, contain...</td>\n",
              "      <td>147605.0</td>\n",
              "      <td>2023-03-05T03:10:27.593</td>\n",
              "      <td>High metrics value (MAE, MSE, RMSE)</td>\n",
              "      <td>&lt;python&gt;&lt;pandas&gt;&lt;machine-learning-model&gt;&lt;linea...</td>\n",
              "      <td>...</td>\n",
              "      <td>CC BY-SA 4.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>None</td>\n",
              "      <td>NaN</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>NaN</td>\n",
              "      <td>I'm working with a dataset of cars, containing...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>75561 rows × 23 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3768f831-a51f-41d0-99d7-df8b1979ba69')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-3768f831-a51f-41d0-99d7-df8b1979ba69 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-3768f831-a51f-41d0-99d7-df8b1979ba69');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "           Id  PostTypeId             CreationDate  Score  ViewCount  \\\n",
              "0           5           1  2014-05-13T23:58:30.457      9      898.0   \n",
              "1           7           1  2014-05-14T00:11:06.457      4      478.0   \n",
              "2           9           2  2014-05-14T00:36:31.077      5        NaN   \n",
              "3          10           2  2014-05-14T00:53:43.273     13        NaN   \n",
              "4          14           1  2014-05-14T01:25:59.677     26     1901.0   \n",
              "...       ...         ...                      ...    ...        ...   \n",
              "75722  119962           1  2023-03-04T20:06:06.820      0        8.0   \n",
              "75723  119963           1  2023-03-04T20:12:19.677      0       10.0   \n",
              "75724  119964           1  2023-03-05T00:14:12.597      0        7.0   \n",
              "75725  119965           1  2023-03-05T00:43:12.213      0        5.0   \n",
              "75726  119966           1  2023-03-05T03:10:27.593      0        2.0   \n",
              "\n",
              "                                                    Body  OwnerUserId  \\\n",
              "0      <p>I've always been interested in machine lear...          5.0   \n",
              "1      <p>As a researcher and instructor, I'm looking...         36.0   \n",
              "2      <p>Not sure if this fits the scope of this SE,...         51.0   \n",
              "3      <p>One book that's freely available is \"The El...         22.0   \n",
              "4      <p>I am sure data science as will be discussed...         66.0   \n",
              "...                                                  ...          ...   \n",
              "75722  <p>I am implementing a neural network of arbit...     147597.0   \n",
              "75723  <p>I am using KNN for a regression task</p>\\n<...     147598.0   \n",
              "75724  <p>I have developed a small encoding algorithm...      44581.0   \n",
              "75725  <p>To my understanding, optimizing a model wit...      84437.0   \n",
              "75726  <p>I'm working with a dataset of cars, contain...     147605.0   \n",
              "\n",
              "              LastActivityDate  \\\n",
              "0      2014-05-14T00:36:31.077   \n",
              "1      2014-05-16T13:45:00.237   \n",
              "2      2014-05-14T00:36:31.077   \n",
              "3      2014-05-14T00:53:43.273   \n",
              "4      2020-08-16T13:01:33.543   \n",
              "...                        ...   \n",
              "75722  2023-03-04T20:22:12.523   \n",
              "75723  2023-03-04T20:12:19.677   \n",
              "75724  2023-03-05T00:14:12.597   \n",
              "75725  2023-03-05T00:43:12.213   \n",
              "75726  2023-03-05T03:10:27.593   \n",
              "\n",
              "                                                   Title  \\\n",
              "0      How can I do simple machine learning without h...   \n",
              "1      What open-source books (or other materials) pr...   \n",
              "2                                                   None   \n",
              "3                                                   None   \n",
              "4               Is Data Science the Same as Data Mining?   \n",
              "...                                                  ...   \n",
              "75722  Back Propagation on arbitrary depth network wi...   \n",
              "75723                        Evaluation parameter in knn   \n",
              "75724  Can I use zero-padded input and output layers ...   \n",
              "75725  Why does cross validation and hyperparameter t...   \n",
              "75726                High metrics value (MAE, MSE, RMSE)   \n",
              "\n",
              "                                                    Tags  ...  ContentLicense  \\\n",
              "0                                     <machine-learning>  ...    CC BY-SA 3.0   \n",
              "1                               <education><open-source>  ...    CC BY-SA 3.0   \n",
              "2                                                   None  ...    CC BY-SA 3.0   \n",
              "3                                                   None  ...    CC BY-SA 3.0   \n",
              "4                             <data-mining><definitions>  ...    CC BY-SA 3.0   \n",
              "...                                                  ...  ...             ...   \n",
              "75722                  <neural-network><backpropagation>  ...    CC BY-SA 4.0   \n",
              "75723                                 <regression><k-nn>  ...    CC BY-SA 4.0   \n",
              "75724      <deep-learning><convolutional-neural-network>  ...    CC BY-SA 4.0   \n",
              "75725          <cross-validation><hyperparameter-tuning>  ...    CC BY-SA 4.0   \n",
              "75726  <python><pandas><machine-learning-model><linea...  ...    CC BY-SA 4.0   \n",
              "\n",
              "       AcceptedAnswerId LastEditorUserId             LastEditDate  ParentId  \\\n",
              "0                   NaN              NaN                     None       NaN   \n",
              "1                  10.0             97.0  2014-05-16T13:45:00.237       NaN   \n",
              "2                   NaN              NaN                     None       5.0   \n",
              "3                   NaN              NaN                     None       7.0   \n",
              "4                  29.0            322.0  2014-06-17T16:17:20.473       NaN   \n",
              "...                 ...              ...                      ...       ...   \n",
              "75722               NaN         147597.0  2023-03-04T20:22:12.523       NaN   \n",
              "75723               NaN              NaN                     None       NaN   \n",
              "75724               NaN              NaN                     None       NaN   \n",
              "75725               NaN              NaN                     None       NaN   \n",
              "75726               NaN              NaN                     None       NaN   \n",
              "\n",
              "       OwnerDisplayName CommunityOwnedDate  LastEditorDisplayName  \\\n",
              "0                  None               None                   None   \n",
              "1                  None               None                   None   \n",
              "2                  None               None                   None   \n",
              "3                  None               None                   None   \n",
              "4                  None               None                   None   \n",
              "...                 ...                ...                    ...   \n",
              "75722              None               None                   None   \n",
              "75723              None               None                   None   \n",
              "75724              None               None                   None   \n",
              "75725              None               None                   None   \n",
              "75726              None               None                   None   \n",
              "\n",
              "      FavoriteCount                                       cleaned_body  \n",
              "0               NaN  I've always been interested in machine learnin...  \n",
              "1               NaN  As a researcher and instructor, I'm looking fo...  \n",
              "2               NaN  Not sure if this fits the scope of this SE, bu...  \n",
              "3               NaN  One book that's freely available is \"The Eleme...  \n",
              "4               NaN  I am sure data science as will be discussed in...  \n",
              "...             ...                                                ...  \n",
              "75722           NaN  I am implementing a neural network of arbitrar...  \n",
              "75723           NaN  I am using KNN for a regression task It's like...  \n",
              "75724           NaN  I have developed a small encoding algorithm th...  \n",
              "75725           NaN  To my understanding, optimizing a model with k...  \n",
              "75726           NaN  I'm working with a dataset of cars, containing...  \n",
              "\n",
              "[75561 rows x 23 columns]"
            ]
          },
          "execution_count": 109,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "posts"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9vYfAFcDe_ER"
      },
      "source": [
        "You can also implement a function that cleans the user's query (the query). \n",
        "\n",
        "This step is optionnal (if you don't think that it is necessary, just return the query)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 110,
      "metadata": {
        "id": "Q8_gvmjXwBwt"
      },
      "outputs": [],
      "source": [
        "def clean_query(text:str)->str:\n",
        "    #TODO\n",
        "    return cleaned_query"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BnjdSpeLlZzJ"
      },
      "source": [
        "## Text specific metadata"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qEyQEpoaoGLY"
      },
      "source": [
        "What metadata can you get from the text at your disposal ? Which ones are relevant ? "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 111,
      "metadata": {
        "id": "5b_O0YS-oMAh"
      },
      "outputs": [],
      "source": [
        "#TODO\n",
        "#The relevant metadata are the title, the tags, the CreationDate and the LastEditDate/last activity Date,\n",
        "# the ViewCount, the favoriteCount, the owner user ID (to be linked withe the table user)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o0rsRxD4xeli"
      },
      "source": [
        "## Classic Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NLmg2T3qxjc3"
      },
      "source": [
        "The goal for this part is to implement a classic vectorization (Count vectorizer, tfidf...).\n",
        "\n",
        "You can do it on your own or use scikit-learn.\n",
        "\n",
        "Hints : pay attention to stopwords, additionnal preprocessing steps and techniques of vectoriation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 112,
      "metadata": {
        "id": "VTaWk2nAAiTj"
      },
      "outputs": [],
      "source": [
        "vectorizer = TfidfVectorizer()\n",
        "docs=posts.cleaned_body.values.tolist() #liste de chaine des caratères\n",
        "vectorizer.fit_transform(docs)\n",
        "vectors = vectorizer.transform(posts.cleaned_body.values)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "drg1x_9v1RD6"
      },
      "source": [
        "Write a function that applies the same process to the query\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 113,
      "metadata": {
        "id": "RpBr0mfF1QVr"
      },
      "outputs": [],
      "source": [
        "def vectorize_query(query : str, vectorizer=vectorizer):\n",
        "    \"\"\"vectorizes the query\n",
        "    Args:\n",
        "        query (str): query string\n",
        "        vectorizer (optional): Defaults to vectorizer.\n",
        "\n",
        "    Returns:\n",
        "        query vectorized\n",
        "    \"\"\"\n",
        "    query_vectorized=vectorizer.transform([query])\n",
        "\n",
        "    return query_vectorized"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZO5uBYas15HS"
      },
      "source": [
        "Determine a way to use this vectorization to suggest the closest items to the entry in the database"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 114,
      "metadata": {
        "id": "X2JhLiCU1NPu"
      },
      "outputs": [],
      "source": [
        "def vectorizer_search(query : str,\n",
        "                      vectors=vectors,\n",
        "                      vectorizer=vectorizer) -> list:\n",
        "    # Vectorize the query\n",
        "    query_vectorized = vectorize_query(query, vectorizer)\n",
        "\n",
        "    # Calculate the similarity between the query vector and all database vectors\n",
        "    similarity_scores = cosine_similarity(query_vectorized, vectors)\n",
        "\n",
        "    # Get the indices of the closest items based on similarity scores\n",
        "    closest_indices = np.argsort(similarity_scores, axis=1)[0][::-1]\n",
        "\n",
        "    # Get the closest items from the database\n",
        "    closest_items = [docs[i] for i in closest_indices]\n",
        "\n",
        "    return closest_items"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 115,
      "metadata": {
        "id": "FHVHzd-G3Sd0"
      },
      "outputs": [],
      "source": [
        "entry = 'what is stochastic gradient descent ?'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 116,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ir0QIX-XGE-N",
        "outputId": "38feefdc-3c26-44a4-aad5-fb059e52e51c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['As I know, Gradient Descent has three variants which are: 1- Batch Gradient Descent: processes all the training examples for each iteration of gradient descent. 2- Stochastic Gradient Descent: processes one training example per iteration. Hence, the parameters are being updated even after one iteration in which only a single example has been processed. 3- Mini Batch gradient descent: which works faster than both batch gradient descent and stochastic gradient descent. Here, b examples where b < m are processed per iteration. But in some cases they use Stochastic Gradient Descent and they define a batch size for training which is what I am confused about. Also, what about Adam, AdaDelta & AdaGrad, are they all mini-batch gradient descent or not? ',\n",
              " 'What is the difference between Gradient Descent and Stochastic Gradient Descent? I am not very familiar with these, can you describe the difference with a short example? ',\n",
              " 'Both algorithms are quite similar. The only difference comes while iterating. In Gradient Descent, we consider all the points in calculating loss and derivative, while in Stochastic gradient descent, we use single point in loss function and its derivative randomly. Check out these two articles, both are inter-related and well explained. I hope it helps. Gradient Descent algorithm Stochastic Gradient Descent. ']"
            ]
          },
          "execution_count": 116,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        " vectorizer_search(entry)[:3]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3AcnQSRd7XJz"
      },
      "source": [
        "How you can improve this approach ? "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fi4Y1vsqB_Sw"
      },
      "source": [
        "Answer here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hWNZJR6qYwcT"
      },
      "source": [
        "## Semantic similarity"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6hbMp61saeBm"
      },
      "source": [
        "There are NLP methods that go further than word-by-word study, by taking into account the context of the terms. There are several methods: Word2vec, Bert.\n",
        "\n",
        "From the Sentence Transformers documentation: https://www.sbert.net/docs/pretrained_models.html choose the pre-trained model that you think is the most appropriate. Justify your choice."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 117,
      "metadata": {
        "id": "gOLIblKWCSQ1"
      },
      "outputs": [],
      "source": [
        "sentence_transformer_model = 'all-MiniLM-L6-v2'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8O6QZfgPCKMk"
      },
      "source": [
        "Answer Here"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 118,
      "metadata": {
        "id": "5KEamS2M4DS-"
      },
      "outputs": [],
      "source": [
        "#Pertinence du domaine : Étant donné que votre base de données est constituée de documents\n",
        "# liés à la science des données, un modèle qui a été affiné pour des tâches de NLI à l'aide \n",
        "#de textes divers devrait capturer les subtilités et le contexte propres au domaine de la \n",
        "#science des données.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6r2keNXSeQ1J"
      },
      "source": [
        "⚠ To use Sentence Transformers it is recommended to activate the GPU of google colab."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 119,
      "metadata": {
        "id": "dCTzpEkkeQAO"
      },
      "outputs": [],
      "source": [
        "MODEL_ST = SentenceTransformer(sentence_transformer_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ph24xTeVgTpU"
      },
      "source": [
        "Use this algorithm to encode the data in the database"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 120,
      "metadata": {
        "id": "v-TTENiM5vn2"
      },
      "outputs": [],
      "source": [
        "#embeddings = MODEL_ST.encode(posts.cleaned_body.values, normalize_embeddings=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TBJ0W5UygN9C"
      },
      "source": [
        "*If this process is slow, you can save this array in case you need to load it again*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 121,
      "metadata": {
        "id": "Qkw285npGxmY"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "\n",
        "#with open(os.path.join(DATA_PATH, 'embeddings.pkl'), 'wb') as file:\n",
        "#   pickle.dump(embeddings, file)\n",
        "\n",
        "L=[]\n",
        "with open(os.path.join(DATA_PATH, 'embeddings.pkl'),'rb') as file:\n",
        "    embeddings=pickle.load(file)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Hy__GOwgbIG"
      },
      "source": [
        "Make a function that transforms the input"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 122,
      "metadata": {
        "id": "35As3cuYgRWq"
      },
      "outputs": [],
      "source": [
        "def encode_query(query : str) ->  np.ndarray:\n",
        "    encoded_query = MODEL_ST.encode([query], normalize_embeddings=True)\n",
        "    return encoded_query"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xFD6pJIpgEz8"
      },
      "source": [
        "Which distance is most relevant to measure the distance between the input and the data?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 123,
      "metadata": {
        "id": "joJ1SABq-VIr"
      },
      "outputs": [],
      "source": [
        "#la mesure cosinus"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6LxvJiVKIv-V"
      },
      "source": [
        "Write a function that returns a matrix containing information about the similarity between the query and the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 124,
      "metadata": {
        "id": "ZtDl3Cicf9wd"
      },
      "outputs": [],
      "source": [
        "def similarity(query, embeddings=embeddings):\n",
        "    encoded_query=encode_query(query)\n",
        "    return cosine_similarity(encoded_query, embeddings)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 125,
      "metadata": {
        "id": "_oR0xnZCJKfc"
      },
      "outputs": [],
      "source": [
        "query = 'what is stochastic gradient descent ?'\n",
        "matrix_similarity = similarity(query, embeddings)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2dRGokvThOcs"
      },
      "source": [
        "How do you determine which documents in the data set most closely match the input?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 126,
      "metadata": {
        "id": "jd1UD26VhN_9"
      },
      "outputs": [],
      "source": [
        "def ordre_en_fonction_similarité(matrix_similarity):\n",
        "    # Get the indices of the documents sorted by their similarity scores\n",
        "    sorted_indices = np.argsort(matrix_similarity)[::-1]\n",
        "\n",
        "    return sorted_indices"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 127,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9-CoY6VUj5EE",
        "outputId": "53855d19-3ade-4842-d4b8-6c2ab006b8de"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([1, 2, 0])"
            ]
          },
          "execution_count": 127,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ordre_en_fonction_similarité([0.6, 0.8, 0.7])\n",
        "#on doit trouver [1, 2, 0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a3IBMm8HisWy"
      },
      "source": [
        "Put it all together in a function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 128,
      "metadata": {
        "id": "BOFygRpbifXw"
      },
      "outputs": [],
      "source": [
        "def closest_semantic_doc(query, embeddings=embeddings, top_n=10):\n",
        "    matrix_similarity=similarity(query, embeddings)\n",
        "    closest_posts=ordre_en_fonction_similarité(matrix_similarity)[:top_n]\n",
        "    return closest_posts"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ouUjQrhgjEDs"
      },
      "source": [
        "What methods could be used to improve the recommendations of this algorithm?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_v7HI2pDJk-f"
      },
      "source": [
        "Answer here"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 129,
      "metadata": {
        "id": "vNP-BErhJm4N"
      },
      "outputs": [],
      "source": [
        "#We could take into account the metadata, and try to merge different search method (for example BM25 and the semantic search)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fa4Ij2usk8Gb"
      },
      "source": [
        "## Text clustering (BONUS)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EfZcQyxLox8U"
      },
      "source": [
        "We can use topic modeling techniques to identify groups of texts among our document base and classify the input to restrict the application of the proximity calculations seen previously."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kt9_ujt6sVMg"
      },
      "source": [
        "#### LDA"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eH2IG1iyTxiD"
      },
      "source": [
        "Latent Dirichlet Allocation is a topic modeling algorithm that allows soft clustering. Soft clustering means that the LDA does not allocate an input to a cluster, but gives a probabilistic score for each identified cluster. This decomposition allows to identify topics within the documents. \n",
        "\n",
        "In order to compute this algorithm, you need to vectorize your data (you can use the one you have already done previously or make another one)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 145,
      "metadata": {
        "id": "BfpEOZYkk7kH"
      },
      "outputs": [],
      "source": [
        "# Vectorize document using TF-IDF\n",
        "vectorizer_lda =CountVectorizer()\n",
        "\n",
        "#fichier test\n",
        "documents=posts.sample(100).cleaned_body.values\n",
        "\n",
        "# Fit and Transform the documents\n",
        "train_data = vectorizer_lda.fit_transform(documents)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WSZ1kI3JWfTL"
      },
      "source": [
        "You can use Gensim or scikit-learn to compute LDA."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 146,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oDGFnU1CJ6_w",
        "outputId": "ccba8eeb-4658-4d70-f803-263af967abef"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: lda in /usr/local/lib/python3.10/dist-packages (2.0.0)\n",
            "Requirement already satisfied: pbr<4,>=0.6 in /usr/local/lib/python3.10/dist-packages (from lda) (3.1.1)\n",
            "Requirement already satisfied: numpy<2.0,>=1.13.0 in /usr/local/lib/python3.10/dist-packages (from lda) (1.22.4)\n"
          ]
        }
      ],
      "source": [
        "!pip install lda"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 147,
      "metadata": {
        "id": "xlLWISp0w90p"
      },
      "outputs": [],
      "source": [
        "from lda import LDA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 153,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xjrOO3n8xZm9",
        "outputId": "8427b433-5020-4c89-b1d0-6349caf94694"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Topic 0: np, for, reshape, w1, w2\n",
            "Topic 1: of, the, each, value, features\n",
            "Topic 2: topic, in, tensorflow, file, tf_files\n",
            "Topic 3: the, for, network, is, of\n",
            "Topic 4: the, to, is, and, in\n",
            "Topic 5: self, nn, kernel_size, in, model\n",
            "Topic 6: the, activation, layer, model, as\n",
            "Topic 7: tf, time, model, n_hidden, plt\n",
            "Topic 8: theta, am, of, in, hidden\n",
            "Topic 9: of, for, as, or, use\n"
          ]
        }
      ],
      "source": [
        "#Initialize the LDA model\n",
        "model = LDA(n_topics=10, n_iter=500)\n",
        "\n",
        "#Training\n",
        "model.fit(train_data)\n",
        "\n",
        "# Get the topic-word distributions\n",
        "topic_word_distributions = model.topic_word_\n",
        "\n",
        "# Infer the document-topic distributions\n",
        "document_topic_distributions = model.transform(train_data)\n",
        "\n",
        "# Print the top words for each topic\n",
        "for topic_idx, topic_words in enumerate(model.topic_word_):\n",
        "    top_words = [vectorizer_lda.get_feature_names_out()[i] for i in topic_words.argsort()[:-6:-1]]\n",
        "    print(f\"Topic {topic_idx}: {', '.join(top_words)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 156,
      "metadata": {
        "id": "PVcDqyJqA04_"
      },
      "outputs": [],
      "source": [
        "from gensim import corpora, models, matutils"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 158,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "es029fhX9N-U",
        "outputId": "432d6a57-0a10-4058-9c5a-77c7caeaecbb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(0, '0.002*\"10\" + 0.002*\"bin\" + 0.002*\"83\" + 0.002*\"training\" + 0.002*\"label\" + 0.001*\"word\" + 0.001*\"learn\" + 0.001*\"column\" + 0.001*\"performance\" + 0.001*\"probably\"')\n",
            "(1, '0.003*\"tf\" + 0.002*\"age\" + 0.002*\"nn\" + 0.001*\"img\" + 0.001*\"torch\" + 0.001*\"google\" + 0.001*\"errors\" + 0.001*\"soon\" + 0.001*\"scout\" + 0.001*\"isnt\"')\n",
            "(2, '0.002*\"the\" + 0.002*\"move\" + 0.002*\"partition\" + 0.002*\"because\" + 0.002*\"each\" + 0.002*\"is\" + 0.002*\"independence\" + 0.002*\"sigmoid\" + 0.002*\"hidden\" + 0.002*\"function\"')\n",
            "(3, '0.003*\"the\" + 0.002*\"theta\" + 0.002*\"self\" + 0.002*\"sentence\" + 0.002*\"to\" + 0.002*\"in\" + 0.002*\"bert\" + 0.002*\"covid\" + 0.002*\"argument\" + 0.002*\"semantic\"')\n",
            "(4, '0.002*\"levels\" + 0.002*\"killed\" + 0.002*\"test\" + 0.002*\"tensorflow\" + 0.002*\"counter\" + 0.002*\"recent_school_shootings\" + 0.001*\"carts\" + 0.001*\"the\" + 0.001*\"sample\" + 0.001*\"dropout\"')\n",
            "(5, '0.002*\"orange\" + 0.002*\"iloc\" + 0.002*\"rattle\" + 0.001*\"x_init\" + 0.001*\"chart\" + 0.001*\"convolution\" + 0.001*\"strides\" + 0.001*\"test_index\" + 0.001*\"train_index\" + 0.001*\"error\"')\n",
            "(6, '0.016*\"the\" + 0.011*\"to\" + 0.009*\"of\" + 0.008*\"is\" + 0.007*\"you\" + 0.007*\"and\" + 0.006*\"for\" + 0.005*\"in\" + 0.005*\"that\" + 0.005*\"it\"')\n",
            "(7, '0.002*\"xgb\" + 0.002*\"layer\" + 0.002*\"svm\" + 0.002*\"cross\" + 0.002*\"df\" + 0.002*\"µs\" + 0.002*\"clf\" + 0.002*\"dimensional\" + 0.001*\"layers\" + 0.001*\"the\"')\n",
            "(8, '0.002*\"scaler\" + 0.002*\"np\" + 0.002*\"api\" + 0.002*\"ratings\" + 0.002*\"seems\" + 0.002*\"the\" + 0.001*\"https\" + 0.001*\"json\" + 0.001*\"quotes\" + 0.001*\"sparse\"')\n",
            "(9, '0.003*\"topic\" + 0.002*\"duration\" + 0.002*\"watch\" + 0.002*\"series\" + 0.001*\"positives\" + 0.001*\"tp\" + 0.001*\"amount\" + 0.001*\"sequence\" + 0.001*\"document\" + 0.001*\"going\"')\n"
          ]
        }
      ],
      "source": [
        "# Initialize TfidfVectorizer\n",
        "vectorizer = TfidfVectorizer()\n",
        "\n",
        "# Create the TF-IDF matrix\n",
        "dtm_tfidf = vectorizer.fit_transform(documents)\n",
        "\n",
        "# Convert the TF-IDF matrix to Gensim corpus\n",
        "corpus = matutils.Sparse2Corpus(dtm_tfidf, documents_columns=False)\n",
        "\n",
        "# Create the Gensim dictionary\n",
        "id2word = dict((i, word) for i, word in enumerate(vectorizer.get_feature_names_out()))\n",
        "\n",
        "# Train the LDA model\n",
        "lda_model = models.LdaModel(corpus=corpus, id2word=id2word, num_topics=10, passes=10)\n",
        "\n",
        "# Print the topics and their top words\n",
        "for topic in lda_model.show_topics():\n",
        "    print(topic)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nG_grQ93tMIB"
      },
      "source": [
        "Assign a main topic to each document"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oO1ZaPy6s6Uf"
      },
      "source": [
        "Write a function that assigns a topic to the query\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n86QrUuus5Bh"
      },
      "outputs": [],
      "source": [
        "def get_topic_query(query, vectorizer=vectorizer_lda, lda_model=lda_model) -> int:\n",
        "    #TODO\n",
        "    return topic_query"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZQfMqiMpvKk5"
      },
      "source": [
        "## Merge methods"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ll1RCEV-vVbJ"
      },
      "source": [
        "Write an algorithm to merge the methods seen. Which methods to use? How can you check if they are relevant ?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-vIibmanKPLC"
      },
      "source": [
        "Answer here"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v2GUl3uHSJej"
      },
      "outputs": [],
      "source": [
        "def nlp_search_algorithm(query,\n",
        "                         topic_documents=topic_documents,\n",
        "                         vectors=vectors,\n",
        "                         vectorizer=vectorizer,\n",
        "                         vectorizer_lda=vectorizer_lda,\n",
        "                         lda_model=lda_model,\n",
        "                         embeddings=embeddings,\n",
        "                         top_n=10\n",
        "                         )->list:\n",
        "    #TODO\n",
        " \n",
        "    return matching_posts\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mWh3EuXiT_Qc"
      },
      "source": [
        "Once you have a list of possible results, you can it: (you can use one of the ranking algorithms you have previously done or make up a new one)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9FbEcpONT-1Z"
      },
      "outputs": [],
      "source": [
        "def rank(possible_results):\n",
        "    #to_do\n",
        "    return possible_results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pJ3vhg1kpX6l"
      },
      "source": [
        "## Incorporation in the search engine"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4CDbNI-qpf3z"
      },
      "source": [
        "### Addition of metadata"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yZBXyHN3MKBx"
      },
      "source": [
        "You must now have a new set of metadata and data to add to your original index. You can load the index you had as a result of Day 2 and today's work to it. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dK9U-NB0MctD"
      },
      "outputs": [],
      "source": [
        "#load previous data \n",
        "\n",
        "#TODO "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yV6jul7jNW7y"
      },
      "outputs": [],
      "source": [
        "# add the new data to the previous index"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HvDxs_EZKyeO"
      },
      "source": [
        "Hint : if you have changed the preprocessing function at the beginning of this notebook make sure to update the Clean Body attribute"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AZ8PuvLBUap8"
      },
      "source": [
        "### Adaptation to the index format\n",
        "\n",
        "Adapt your nlp search results to the index format"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "alY_kdTOUaFa"
      },
      "outputs": [],
      "source": [
        "def nlp_search_in_index(query,\n",
        "                        index,\n",
        "                        args):\n",
        "\n",
        "    return matching_posts\n",
        "  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vPC4lvgeUpAX"
      },
      "source": [
        "### Compare the new searching and ranking method to the previous ones\n",
        "\n",
        "Compare in terms of efficiency (precision, completeness, speed, memory usage)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N_yte-oapjFW"
      },
      "source": [
        "### merge all methods to make an efficient search algorithm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kGcqIGl8pXhX"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CU2e3tgiIHzr"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
